{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### 简介\n",
    "Tokenization 的主要目的是将文本分解成更小的单位(Tokens)，减小模型输入数据的内在结构复杂度(从句子变为单词序列)，从而简化模型训练的难度。同时将字符的序列转化为Token序号的序列，便于模型输入。\n",
    "\n",
    "Tokenization 首先确定语言的词表划分粒度，一般可分为：\n",
    "* 字符级：将文本分解为字符。\n",
    "* 单词级：将文本分解为单词。\n",
    "* 子词级：将单词进一步分解为更小的有意义单元（如前缀、后缀）。\n",
    "\n",
    "之后使用预定义的规则来识别 tokens, 或使用统计或机器学习技术来识别最优的 token 切分方式。例如，BPE（Byte Pair Encoding）或 SentencePiece。\n",
    "\n",
    "最后实现一组文本序列和Tokens序列之间相互转化的函数，即可完成Tokenization部分。\n",
    "\n",
    "### 实验要求\n",
    "\n",
    "1. 实现字符级切分的简单tokenizer， 由 字符表， 字符到token的 encoder()函数 和 token到字符的 decoder() 函数组成。\n",
    "2. 调用 现有的tokenizer实现，比如openai 的tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataPath:str\n",
    "        ):\n",
    "        with open(dataPath,\"r\",encoding=\"utf-8\") as f:\n",
    "            self.dataset = f.read()\n",
    "        self.generate_vocabulary()\n",
    "\n",
    "    def generate_vocabulary(\n",
    "        self,\n",
    "        ):\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        \"\"\"\n",
    "        unique_chars = list(set(self.dataset))\n",
    "        unique_chars.sort()\n",
    "        for i, char in enumerate(unique_chars):\n",
    "            self.char2index[char] = i+1\n",
    "            self.index2char[i+1] = char\n",
    "        self.index2char[0] = \" \"\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        sentence : str,\n",
    "        ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input  : \"ABCD\"\n",
    "        output : Tensor([0,1,2,3]) \n",
    "\n",
    "        注意: 为了后续实验方便，输出Tensor的数据类型dtype 为torch.long。\n",
    "        \"\"\"\n",
    "        sentence = [self.char2index[char] for char in sentence]\n",
    "        sentence = [0] + sentence\n",
    "        return torch.tensor(sentence, dtype=torch.long, device=device)\n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        tokens : torch.Tensor,\n",
    "        ) -> str:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input : Tensor([0,1,2,3]) \n",
    "        output : \"ABCD\"\n",
    "        \"\"\"\n",
    "        sentence = [self.index2char[index] for index in tokens]\n",
    "        sentence = sentence[1:]\n",
    "        return \"\".join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 dataloader 和 dataset\n",
    "\n",
    "为了高效加载数据，我们需要把输入文件接入 PyTorch 的数据加载器中。在这里我们定义 `ShakespeareDataset` 类用于加载数据集，用 PyTorch 的 `DataLoader` 类来实现数据加载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, filepath, tokenizer, chunk_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        text = \"\\n\".join([line for line in text.splitlines() if line.strip()])\n",
    "        text = re.sub(r'^.*:$', '', text, flags=re.MULTILINE)\n",
    "        text = \"\\n\".join([line for line in text.splitlines() if line.strip()])\n",
    "        self.encoded = self.tokenizer.encode(text)\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded) - self.chunk_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: 提取一段文本(长度为 chunk_size）作为输入，以及这段文本的每一个字符的下一个字符作为标签\n",
    "        # example(not correspond to real text): chunk = tensor([ 0, 20, 49, 58, 59])\n",
    "        #         label = tensor([20, 49, 58, 59, 19])\n",
    "        # decoded chunk: \"The \"\n",
    "        # decoded label: \"he T\"\n",
    "        chunk = self.encoded[idx:idx+self.chunk_size]\n",
    "        label = self.encoded[idx+1:idx+self.chunk_size+1]\n",
    "\n",
    "        return chunk, label\n",
    "\n",
    "tokenizer = Tokenizer(dataPath=\"input.txt\")\n",
    "\n",
    "def create_dataloader(filepath, tokenizer, chunk_size, batch_size, shuffle=True):\n",
    "    dataset = ShakespeareDataset(filepath, tokenizer, chunk_size)\n",
    "    train_dataset,val_dataset = torch.utils.data.random_split(dataset,[int(len(dataset)*0.8),len(dataset)-int(len(dataset)*0.8)])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "train_dataloader,val_dataloader = create_dataloader('input.txt', tokenizer, chunk_size=200, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力的计算公式为：\n",
    "$$\n",
    "Head = Attention(x)=Softmax(M\\cdot QK^T)V\\\\\n",
    "Q=xW_{q},K=xW_{k}, V=xW_{v}\n",
    "$$\n",
    "这里实现的一些数学技巧可以参见attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadAttention(nn.Module):\n",
    "    def __init__(self, seq_len:int, embed_size:int, hidden_size:int):\n",
    "        super().__init__()\n",
    "        # embed_size: dimension for input embedding vector\n",
    "        # hidden_size: dimension for hidden vector. eg. x:(..., embed_size) --to_q--> query_vector:(..., hidden_size)\n",
    "\n",
    "        # a triangular bool matrix for mask\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(seq_len, seq_len)))\n",
    "        \n",
    "        # TODO: init three matrix, to_q, to_k, to_v.\n",
    "        self.to_q = nn.Linear(embed_size, hidden_size)\n",
    "        self.to_k = nn.Linear(embed_size, hidden_size)\n",
    "        self.to_v = nn.Linear(embed_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size)\n",
    "        # return (batch_size, seq_len, hidden_size)\n",
    "        # TODO: implement the attention mechanism\n",
    "        q = self.to_q(inputs)\n",
    "        k = self.to_k(inputs)\n",
    "        v = self.to_v(inputs)\n",
    "\n",
    "        # q, k, v: (batch_size, seq_len, hidden_size)\n",
    "        # attn: (batch_size, seq_len, seq_len)\n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) / (k.size(-1) ** 0.5)\n",
    "        attn = attn.masked_fill(self.tril == 0, float('-inf'))\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        return torch.bmm(attn, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer中使用的注意力机制时会使用多个注意力头，期望每个注意力头能够注意到不同的信息。\n",
    "所以实际公式需要修改如下\n",
    "$$\n",
    "MultiHeadAttention(x)=[Head_0, Head_1,...,Head_h]W_o\\\\\n",
    "Head_i = Attention(x)=Softmax(M\\cdot Q_iK_i^T)V_i\\\\\n",
    "Q_i=xW_{iq},K=xW_{ik}, V=xW_{iv}\n",
    "$$\n",
    "在搭建网络的过程中，同学们可能会用到nn.ModuleList这个库，每个$Head_i$的计算可以直接使用上面已经实现的单头注意力计算。\n",
    "最后对于这些注意力头再使用一个简单的线性层/矩阵$W_o$汇总信息即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    # MultiHeadAttention is consist of many HeadAttention output.\n",
    "    # concat all this head attention output o_i, then merge them with a projection matrix W_o, as [o_1, o_2, ...] x W_o\n",
    "    # The reason for using multi-head attention is that we want each head to be able to extract different features\n",
    "    def __init__(self, n_heads:int, head_size:int, seq_len:int, embed_size:int):\n",
    "        # n_heads is the number of head attention\n",
    "        # head_size is the hidden_size in each HeadAttention\n",
    "        super().__init__()\n",
    "        head_size = embed_size // n_heads\n",
    "        #TODO: implement heads and projection\n",
    "        self.heads = nn.ModuleList([HeadAttention(seq_len, embed_size, head_size) for _ in range(n_heads)])\n",
    "        self.projection = nn.Linear(n_heads * head_size, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size), make sure embed_size=n_heads x head_size\n",
    "        # return: (batch_size, seq_len, embed_size)\n",
    "        # TODO:\n",
    "        head_outputs = [head(inputs) for head in self.heads]\n",
    "        return self.projection(torch.cat(head_outputs, dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 专家网络 Expert\n",
    "\n",
    "Expert即为标准Transformer中的FeedForward模块。\n",
    "\n",
    "在经过MultiHeadAttention 模块后，seq_len中的每一个Embedding都对应了前文信息的加权求和。在经过FeedForward模块时，模型对每一个位置的Embedding进行了两次线性变换和一次非线性变换，可以视为对当前语境下的信息进行加工。知识编辑的一些研究表明，FeedForword 模块参数包含了大量的事实性知识。\n",
    "\n",
    "一个直观的想法是，类比于MultiHeadAttention，我们在每一层训练多个FeedForward模块，对于不同位置的Embedding使用不同的FeedForward模块处理对应的信息。就好像每层有多个Expert,每个Expert都负责处理一类数据的深加工，因此我们称FeedForward为Expert。\n",
    "\n",
    "实现方面:\n",
    "\n",
    "FeedForward层由两层简单的线性层组成，对于一个(batch_size, seq_len, embed_size)输入的向量x\n",
    "只在最后一个维度上进行计算，以实现词的特征维度上的交互(注意力机制是词之间的交互)。\n",
    "其首先用一个线性层将x最后一维扩大至原先4倍，然后继续用一个线性层还原回原先的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, embed_size:int):\n",
    "        super().__init__()\n",
    "        #TODO: init two linear layer\n",
    "        self.fc1 = nn.Linear(embed_size, 4*embed_size)\n",
    "        self.fc2 = nn.Linear(4*embed_size, embed_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs: (batch_size, seq_len, embed_size)\n",
    "        # -> mid: (batch_size, seq_len, 4 x embed_size)\n",
    "        # -> outputs: (batch_size, seq_len, embed_size)\n",
    "        mid = F.relu(self.fc1(inputs))\n",
    "        return self.fc2(mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选通网络 TopkRouter\n",
    "\n",
    "在实现了单个Expert后，我们要设计一个选通网络决策每个Embedding要使用那个Expert计算\n",
    "\n",
    "\n",
    "### 为了说明选通网络的实现方式，我们定义一下记号：\n",
    "\n",
    "inputs.shape = [batch_size, seq_len, embed_size] = [1, 8, 16] \n",
    "\n",
    "即输入有batch_size=1个数据点，该数据有seq_len长度的context，即包含seq_len=8个Embedding，每个Embedding长度为embed_dim=16。\n",
    "\n",
    "记 num_expert = 4, 即该层包含 num_expert 个并列的Expert。\n",
    "\n",
    "记 active_expert = 2, 即计算每个Embedding仅有 active_expert 个Expert 参与计算。\n",
    "\n",
    "### 选通网络计算\n",
    "对于有seq_len=8的数据，如果每个Expert都参与计算每一个Embedding，那么一共需要计算 seq_len*embed_size = 32 次， 这极大的增加了模型计算量，因此我们往往只激活其中的active_experts个Expert，这要求我们对每一个Embedding计算最合适的active_experts个 Expert。\n",
    "\n",
    "对于单个Expert 的原版Transformer来说：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = FeedForward(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "对于多个Expert的网络：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = \\sum_{i \\in range(num\\_model)} \\alpha_{i} Expert_{i}(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha_{i} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "    1 & Expert_{i}  \\text{is selected} \\\\\n",
    "    0 & Expert_{i}  \\text{is not selected} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "将$\\{\\alpha_0,\\alpha_1,\\dots,\\alpha_{num_experts-1}\\}$记为向量$\\alpha$:\n",
    "$$\n",
    "outputs[0,seq] = \\alpha \\cdot \\{Expert_i(inputs[0,seq])\\}\n",
    "$$\n",
    "\n",
    "一个选通0,2号Expert的$\\alpha$的例子是$[1,0,1,0]$\n",
    "\n",
    "问题在于如何求得 $\\alpha$, 对于一个Embedding ，我们使用神经网络对每个Expert打分，在根据分数计算$\\alpha$\n",
    "\n",
    "$$\n",
    "score[0,seq] = MLP(inputs[0,seq])  \\\\\n",
    "\\alpha = topK(score[0,seq])\n",
    "$$\n",
    "\n",
    "例如：\n",
    "\n",
    "$$\n",
    "score[0,seq] = [11.32,1.54,14.83,-1.90] \\\\\n",
    "\\alpha = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "从优化的角度来说，$\\alpha$取前k大的分数的下标（即argmax），这个操作是不可导的，这里我们用之前在\"attention.ipynb\"中提到的技巧处理这里的计算。\n",
    "\n",
    "$$\n",
    "mask(score[0,seq]) = [11.32,-inf,14.83,-inf] \\\\\n",
    "\\alpha = softmax(mask(score[0,seq])) = [0.028,0,0.971,0] \\\\\n",
    "index = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "我们用这个$\\alpha$和$index$用做选通网络."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First define the top k router module\n",
    "class TopkRouter(nn.Module):\n",
    "    def __init__(self, embed_size, num_experts, active_experts):\n",
    "        ## TODO\n",
    "        ## embed_size : dimension of embedding \n",
    "        ## num_experts : how many Experts per layer\n",
    "        ## active_experts: only active_experts out of num_experts are selected to process Embeddings per token.\n",
    "        super(TopkRouter, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.fc = nn.Linear(embed_size, num_experts)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## TODO\n",
    "        ## 完成这部分时，注意使用Softmax()对router_output做标准化。同时注意这部分所用操作的可导性。\n",
    "        ## 输入值\n",
    "        ## inputs is the output tensor from multihead self attention block, shape (B:batch size, T: seq_len, C: embed_size)\n",
    "        ## 返回值\n",
    "        ## router_output: normalized weight of Experts, 即教程中的 \\alpha\n",
    "        ## indices:   index of selected Experts, 即教程中的 index\n",
    "        router_output = self.softmax(self.fc(inputs))\n",
    "        top_values, indices = torch.topk(router_output, self.active_experts, dim=-1)\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 稀疏专家网络 SparseMoE\n",
    "\n",
    "![moe](./moeSparse.png)\n",
    "\n",
    "在定义完Expert 和 TopkRouter后，我们可以定义SparseMoE模块。\n",
    "\n",
    "在前向过程中，对于inputs.shape = [Batch_size,seq_len,embed_size]第二维度seq_len个Embedding,我们先利用TopkRouter计算出选通专家序号indices以及专家权重router_output。\n",
    "\n",
    "我们将Embedding通过选通的Expert得出active_expert个新的Embedding，然后使用router_output的作为权重对新的Embedding加权求和作为输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMoE(nn.Module):\n",
    "    def __init__(self, embed_size:int, num_experts:int, active_experts:int):\n",
    "        ## TODO\n",
    "        super(SparseMoE, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.experts = nn.ModuleList([Expert(embed_size) for _ in range(num_experts)])\n",
    "        self.router = TopkRouter(embed_size, num_experts, active_experts)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## TODO\n",
    "        router_output, indices = self.router(inputs)\n",
    "        expert_outputs = [expert(inputs) for expert in self.experts]\n",
    "        expert_outputs = torch.stack(expert_outputs, dim=1)\n",
    "        final_output = torch.einsum('bnte,btn->bte', expert_outputs, router_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer由一层层的block堆叠而成，其中每个block的结构从模型的结构图展开中可以看到，由LayerNorm，Masked multi head attention，(SparseMoE)FeedForward组成。\n",
    "\n",
    "对于一个表示句子的输入向量x，其首先会经过Layer Normalization层.\n",
    "Layer Normalization 层对于一个 句子个数x句子长度x单词向量维度 的输入 x, 会在最后两维上进行规范化处理，起到稳定训练的作用。\n",
    "\n",
    "$$\n",
    "LN(x)=\\frac{x-mean(x)}{\\sqrt{var(x)+\\epsilon}}\\cdot\\gamma+\\beta\n",
    "$$\n",
    "\n",
    "其中mean和var都是在最后两个维度上进行的，layernorm的实现同学们可以直接调用nn.LayerNorm\n",
    "经过layernorm层后，再经过Mask multi head attention层之后，会在+号处再次和原始的输入进行相加，这样的做法能够提高训练的稳定性。有兴趣的同学可以从梯度角度思考原因，或者搜索残差连接相关资料进行学习。\n",
    "之后再同样经过一层layernorm和feedforwad之后，就可以得到block块的输出了。\n",
    "即 x' = x+MHA(LN(x)), y = FFN(LN(x'))+x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    # Transformer basic block, consist of MultiHeadAttention, FeedForward and layer normalization\n",
    "    def __init__(self, embed_size:int, n_heads:int, seq_len:int, num_experts:int, active_experts:int):\n",
    "        super().__init__()\n",
    "        # TODO: implement block structure\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.mha = MultiHeadAttention(n_heads, embed_size//n_heads, seq_len, embed_size)\n",
    "        self.ff = SparseMoE(embed_size, num_experts, active_experts)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input: (batch_size, seq_len, embed_size)\n",
    "        #TODO: forward with residual connection\n",
    "        x = self.mha(inputs)\n",
    "        x = self.norm1(x + inputs)\n",
    "        x = self.ff(x)\n",
    "        return self.norm2(x + inputs)\n",
    "\n",
    "class SparseMoETransformer(nn.Module):\n",
    "    # Transformer decoder, consist of \n",
    "    # token embedding layer and position_embedding(position_embedding 可以理解为对位置编码，感兴趣的同学可以查阅原文，这里可以看为vocab_len = seq_len的Embedding)\n",
    "    # a stack of Transformer basic block\n",
    "    # a layernorm and output linear layer\n",
    "    def __init__(self, vocab_size:int, seq_len:int, embed_size:int, n_layers:int, n_heads:int, num_experts:int, active_experts:int):\n",
    "        # vocab_size is the number of word in vocabulary dict\n",
    "        # seq_len is the sequence length/sentence length\n",
    "        # embed_size is the embedding vector dimension\n",
    "        super().__init__()\n",
    "        # TODO: \n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(seq_len, embed_size)\n",
    "        self.blocks = nn.ModuleList([Block(embed_size, n_heads, seq_len, num_experts, active_experts) for _ in range(n_layers)])\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(vocab_size)\n",
    "        self.fc = nn.Linear(embed_size, vocab_size)\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        # labels: the (ground) true output \n",
    "        # TODO: implement the forward function of the transformer\n",
    "\n",
    "        # inputs:(batch_size, seq_len, )\n",
    "        batch_size, seq_len, = inputs.shape\n",
    "        # embedding:(batch_size, seq_len, embed_size)\n",
    "        embedding = self.token_embedding(inputs) + self.position_embedding(torch.arange(seq_len, device=device))\n",
    "\n",
    "        # attens:(batch_size, seq_len, embed_size)\n",
    "        attens = embedding\n",
    "        for block in self.blocks:\n",
    "            attens = block(attens)\n",
    "\n",
    "        # logits:(batch_size, seq_len, vocab_size)\n",
    "        logits = self.fc(attens)\n",
    "        logits = self.norm2(logits)\n",
    "        logits = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # compute the loss\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch_size, seq_len, vocab_size = logits.shape\n",
    "            logits = logits.view(batch_size * seq_len, vocab_size)\n",
    "            labels = labels.view(batch_size * seq_len)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n",
    "        device = next(self.parameters()).device  \n",
    "        inputs = inputs.to(device)\n",
    "        if inputs.size(1) > self.seq_len:\n",
    "            inputs = inputs[:, :self.seq_len]\n",
    "        elif inputs.size(1) < self.seq_len:\n",
    "            inputs = F.pad(inputs, (self.seq_len - inputs.size(1), 0, 0, 0))\n",
    "        generated = inputs\n",
    "        for _ in range(max_new_tokens):\n",
    "            if generated.size(1) > self.seq_len:\n",
    "                generated_input = generated[:, -self.seq_len:]\n",
    "            else:\n",
    "                generated_input = generated\n",
    "            logits, _ = self.forward(generated_input)\n",
    "            last_logits = logits[:, -1, :]  \n",
    "            next_token_ids = torch.argmax(last_logits, dim=-1)  \n",
    "            next_token_ids = next_token_ids.unsqueeze(-1)  \n",
    "            generated = torch.cat([generated, next_token_ids], dim=1)  \n",
    "        return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练循环\n",
    "\n",
    "如果你已经完成了模型定义等内容，训练的过程实际上在高度封装的 Pytorch 库中非常简单, 因为你并不需要写对应的反向传播。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss \n",
    "\n",
    "Loss 用来**衡量**模型预测与真实值之间的**差距**。\n",
    "\n",
    "常见的几个 Loss 函数：\n",
    "\n",
    "* 交叉熵：$\\text{CrossEntropy Loss} = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)$\n",
    "* 均方误差：$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "* 绝对误差：$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y_i}|$\n",
    "\n",
    "不同的 loss 对应不同的优化目标，如果写错 loss 函数会导致模型不收敛/性能很差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练循环\n",
    "\n",
    "当我们写好 Optimizer 和 Loss 之后，对应的训练循环就十分简单了。\n",
    "\n",
    "我们只需要做以下事情：\n",
    "\n",
    "* 从 dataloader 里面拿到一个 batch 的数据以及标签\n",
    "* 将数据送入模型，进行前向传播\n",
    "* 拿到模型输出的 logits\n",
    "* 将 logits 和 标签进行 loss 计算\n",
    "* 用 Optimizer \n",
    "    * 清空梯度\n",
    "    * 反向传播\n",
    "    * 更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epoch, device):\n",
    "    # Optimizer 会根据模型的输出和真实标签计算梯度，然后利用反向传播算法更新模型的参数。\n",
    "    # 在本实验中你可以将 Optimizer 视作黑盒，只需要知道如何使用即可。\n",
    "    # 找一个合适的 Optimizer。对不同的任务，模型，最适合的优化器是不一样的，你可以先尝试最常用的 Adam，如果有兴趣可以看看其他的优化器。\n",
    "    # docs see: https://pytorch.org/docs/stable/optim.html \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    from tqdm import tqdm\n",
    "    for i, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # TODO: implement the training process, and compute the training loss and validation loss\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch} Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, epoch, device):\n",
    "    model.eval()\n",
    "    # TODO: 实现验证函数。与训练函数类似，但不需要计算梯度。\n",
    "    total_loss = 0\n",
    "    from tqdm import tqdm\n",
    "    for i, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, loss = model(inputs, targets)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507/1507 [01:28<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 1.8221405010470193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377/377 [00:06<00:00, 54.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss: 1.8221405010470193, Valid Loss: 1.5178581960005217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507/1507 [01:27<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.4471923561387292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377/377 [00:06<00:00, 56.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 1.4471923561387292, Valid Loss: 1.4064573049545288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507/1507 [01:26<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1.3656040749647955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377/377 [00:06<00:00, 54.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train Loss: 1.3656040749647955, Valid Loss: 1.3518719824935144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507/1507 [01:28<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.3148673477755055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377/377 [00:07<00:00, 53.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train Loss: 1.3148673477755055, Valid Loss: 1.302778173504837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507/1507 [01:28<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 1.2744213727110651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377/377 [00:06<00:00, 54.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train Loss: 1.2744213727110651, Valid Loss: 1.2671949262644315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1040/829430014.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could pick my lance.\n",
      "What is the state of the commons of the consuls\n",
      "With the seas of the world of the commons\n",
      "That the\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader('input.txt', tokenizer, chunk_size=50, batch_size=512)\n",
    "model = SparseMoETransformer(vocab_size=len(tokenizer.char2index)+1, seq_len=50, embed_size=64, n_layers=3, n_heads=8, num_experts=8, active_experts=2).to(device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(train_loss, valid_loss):\n",
    "    plt.plot(train_loss, label='train')\n",
    "    plt.plot(valid_loss, label='valid')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 训练模型\n",
    "def run(model, train_dataloader, valid_dataloader, device, epochs=10):\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_dataloader, epoch, device)\n",
    "        valid_loss = validate(model, valid_dataloader, epoch, device)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        print(f'Epoch {epoch} Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "    plot_loss(train_loss_list, valid_loss_list)\n",
    "\n",
    "#TODO: 用 matplotlib plot 训练过程中的 loss 变化\n",
    "\n",
    "train_dataloader, val_dataloader = dataloader\n",
    "\n",
    "run(model, train_dataloader, val_dataloader, device, epochs=5)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "print(tokenizer.decode(model.generate(\"I could pick my lance\",max_new_tokens=100)[0].tolist()).strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
